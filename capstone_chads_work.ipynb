{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae0f6a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LLM Client configured: Using 'openai' with model 'gpt-4o'\n"
     ]
    }
   ],
   "source": [
    "# LOADING THE UTILS MODULE\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    # Assumes the notebook is in 'labs/Day_01_.../'\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    # Fallback for different execution environments\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, clean_llm_output\n",
    "\n",
    "# Initialize the LLM client. You can change the model here.\n",
    "# For example: setup_llm_client(model_name=\"gemini-2.5-flash\")\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad97a8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Brainstorming content ---\n",
      "### Minimum Viable Features for a RAG-Powered Documentation Chatbot for CUDA\n",
      "\n",
      "1. **Natural Language Processing (NLP) Capabilities**\n",
      "   - Ability to understand and interpret user queries about CUDA.\n",
      "   - Support for synonyms and technical jargon related to CUDA.\n",
      "\n",
      "2. **Document Retrieval and Processing**\n",
      "   - Integration with CUDA documentation and relevant resources.\n",
      "   - Efficient retrieval of relevant information from large datasets.\n",
      "\n",
      "3. **Answer Generation**\n",
      "   - Generation of concise and accurate responses based on retrieved information.\n",
      "   - Ability to synthesize information from multiple documents to provide comprehensive answers.\n",
      "\n",
      "4. **Real-Time Interaction**\n",
      "   - Quick response time to user queries.\n",
      "   - Continuous learning from user interactions to improve response accuracy.\n",
      "\n",
      "5. **User-Friendly Interface**\n",
      "   - Chat interface that is intuitive and easy to navigate.\n",
      "   - Support for both text and voice input.\n",
      "\n",
      "6. **Contextual Understanding**\n",
      "   - Maintenance of context to handle follow-up questions effectively.\n",
      "   - Ability to handle multi-turn conversations without losing track of the topic.\n",
      "\n",
      "7. **Feedback Mechanism**\n",
      "   - Allow users to provide feedback on the quality of responses.\n",
      "   - Use feedback to refine and improve the chatbot's performance over time.\n",
      "\n",
      "8. **Error Handling**\n",
      "   - Graceful handling of misunderstandings or errors.\n",
      "   - Suggestions for rephrasing or clarifying user queries.\n",
      "\n",
      "9. **Security and Privacy**\n",
      "   - Secure handling of user data and interaction logs.\n",
      "   - Compliance with relevant data protection regulations.\n",
      "\n",
      "### User Stories\n",
      "\n",
      "1. **As a CUDA Developer, I want to ask technical questions about CUDA programming so that I can quickly find solutions to my coding problems.**\n",
      "\n",
      "2. **As a New User, I want to understand the basics of CUDA through a conversational interface so that I can learn effectively without reading through extensive documentation.**\n",
      "\n",
      "3. **As a Researcher, I want to find specific information on CUDA-related publications and papers so that I can gather insights for my work.**\n",
      "\n",
      "4. **As an Educator, I want to recommend the chatbot to my students learning CUDA so that they have a reliable resource for answering their queries.**\n",
      "\n",
      "5. **As a User, I want to provide feedback on the chatbot’s responses so that I can help improve its accuracy and relevance for future users.**\n",
      "\n",
      "6. **As a Project Manager, I want the chatbot to handle frequent and repetitive queries so that my team can focus on more complex tasks.**\n",
      "\n",
      "7. **As a User, I want to receive suggestions for related topics or advanced CUDA features so that I can expand my knowledge beyond my initial query.**\n",
      "\n",
      "8. **As a Business Analyst, I want insights into common queries and trends from users interacting with the chatbot so that I can identify areas for improvement in our documentation.**\n",
      "# Product Requirements Document (PRD) for RAG-Powered Documentation Chatbot\n",
      "\n",
      "## 1. Introduction\n",
      "\n",
      "### Overview\n",
      "The RAG-Powered Documentation Chatbot is a web-based tool designed to assist new and existing developers in learning and solving problems related to CUDA programming. Utilizing a Retrieval-Augmented Generation (RAG) backend, the chatbot will provide precise, contextually relevant answers to queries about the official CUDA C++ Programming Guide. This tool aims to streamline the learning process, reduce time spent searching for information, and enhance user comprehension of CUDA concepts and best practices.\n",
      "\n",
      "### Objectives\n",
      "- To provide quick, accurate, and contextually relevant answers to CUDA-related questions.\n",
      "- To assist new developers in learning CUDA programming more efficiently.\n",
      "- To reduce the need for external resources by centralizing information access through the chatbot.\n",
      "- To improve user engagement and satisfaction by offering a seamless, interactive learning experience.\n",
      "\n",
      "## 2. User Stories\n",
      "\n",
      "### User Story 1: New CUDA Developer Seeking Basic Understanding\n",
      "- **As a** new CUDA developer,\n",
      "- **I want** to ask questions about basic CUDA concepts,\n",
      "- **So that** I can understand the foundational knowledge required to begin programming in CUDA.\n",
      "\n",
      "### User Story 2: Developer Debugging CUDA Code\n",
      "- **As a** developer encountering an issue with my CUDA code,\n",
      "- **I want** to ask the chatbot for potential causes and solutions,\n",
      "- **So that** I can quickly resolve issues and continue my work.\n",
      "\n",
      "### User Story 3: Developer Optimizing CUDA Performance\n",
      "- **As a** developer aiming to optimize my CUDA code,\n",
      "- **I want** to inquire about best practices and performance optimization techniques,\n",
      "- **So that** I can enhance the efficiency and speed of my CUDA applications.\n",
      "\n",
      "### User Story 4: Experienced Developer Exploring Advanced Topics\n",
      "- **As an** experienced CUDA developer,\n",
      "- **I want** to explore advanced CUDA programming topics,\n",
      "- **So that** I can expand my knowledge and keep up with the latest developments and techniques.\n",
      "\n",
      "## 3. Functional Requirements\n",
      "\n",
      "### 3.1 Natural Language Query Handling\n",
      "- **FR1.1**: The chatbot should accept user inputs in natural language, allowing users to express their queries in a conversational manner.\n",
      "- **FR1.2**: The chatbot should support queries of varying complexity, from simple questions to complex multi-part inquiries.\n",
      "- **FR1.3**: The chatbot should handle common misspellings and grammatical errors gracefully, providing suggestions or corrections when necessary.\n",
      "\n",
      "### 3.2 Retrieval of Relevant Information from Knowledge Source\n",
      "- **FR2.1**: The chatbot must be integrated with the official CUDA C++ Programming Guide and other relevant CUDA documentation to retrieve information.\n",
      "- **FR2.2**: The chatbot should utilize an efficient search and retrieval mechanism to quickly find relevant sections of the documentation.\n",
      "- **FR2.3**: The system should be capable of updating its knowledge base to reflect the latest version of the CUDA C++ Programming Guide and other resources.\n",
      "\n",
      "### 3.3 Generation of Concise, User-Friendly Responses\n",
      "- **FR3.1**: The chatbot should generate concise, accurate, and user-friendly responses tailored to the user's query.\n",
      "- **FR3.2**: Responses should include direct answers, explanations, or code snippets where appropriate to enhance user understanding.\n",
      "- **FR3.3**: The chatbot should provide follow-up questions or suggestions to guide users towards further relevant information if needed.\n",
      "- **FR3.4**: The chatbot should allow users to rate the usefulness of responses to help refine and improve future interactions.\n",
      "\n",
      "### 3.4 Additional Functionalities\n",
      "- **FR4.1**: The chatbot should support multi-turn conversations, maintaining context across interactions to provide coherent answers.\n",
      "- **FR4.2**: The system should include a feedback mechanism for users to report inaccuracies or suggest improvements to the chatbot's responses.\n",
      "- **FR4.3**: The chatbot should log interactions anonymously for analysis and continuous improvement of the system.\n",
      "\n",
      "## Conclusion\n",
      "This PRD outlines the essential components and functionalities required to develop a RAG-powered Documentation Chatbot for CUDA programming. By addressing the needs of various developer personas, this tool aims to facilitate a more efficient and effective learning experience for CUDA developers.\n",
      "✅ Successfully saved artifact to: artifacts/prd.md\n"
     ]
    }
   ],
   "source": [
    "# PRD GENERATION\n",
    "\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4.1\")\n",
    "problem_statement = \"We need to create RAG powered documentation chatbot for CUDA.\"\n",
    "# This prompt is direct and open-ended, encouraging the LLM to be creative.\n",
    "features_prompt = f\"\"\"\n",
    "Based on the problem statement: '{problem_statement}', brainstorm basic, minimum viable features and user stories for a RAG chatbot for CUDA. \n",
    "Format the output as a simple markdown list.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Brainstorming content ---\")\n",
    "brainstormed_content = get_completion(features_prompt, client, model_name, api_provider)\n",
    "print(brainstormed_content)\n",
    "\n",
    "prd_prompt = f\"\"\"You are a product manager tasked with creating a Product Requirements Document (PRD) for a web-based RAG-Powered \n",
    "Documentation Chatbot. This chatbot uses a Retrieval-Augmented Generation (RAG) backend to answer questions about the \n",
    "official CUDA C++ Programming Guide, specifically to help new developers learn and solve problems related to CUDA programming.\n",
    "\n",
    "Please provide a detailed PRD that includes the following sections:\n",
    "\n",
    "1. **Introduction**: Overview of the project and its objectives.\n",
    "2. **User Stories**: Describe the key user stories that the chatbot should support.\n",
    "3. **Functional Requirements**: We will have these features: Natural language query handling, retrieval of relevant information from a knowledge source, and generation of concise, user-friendly responses.\n",
    "\n",
    "Make the PRD clear, actionable, and tailored for a technical audience interested in CUDA development.\n",
    "\"\"\"\n",
    "\n",
    "simple_prd_output = get_completion(prd_prompt, client, model_name, api_provider)\n",
    "print(simple_prd_output)\n",
    "save_artifact(simple_prd_output, \"artifacts/prd.md\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250c8f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LLM Client configured: Using 'openai' with model 'gpt-4.1'\n",
      "--- Generating Component Diagram ---\n",
      "\n",
      "--- Generated PlantUML Code ---\n",
      "@startuml\n",
      "' Define components\n",
      "package \"Web-Based RAG-Powered Documentation Chatbot\" {\n",
      "  \n",
      "  [User Interface (UI)] as UI\n",
      "  [Backend Service (API Server)] as Backend\n",
      "  [Database/Document Store] as DB\n",
      "  [Language Model (LLM)] as LLM\n",
      "\n",
      "  ' Relationships\n",
      "  UI -down-> Backend : 1. Sends user queries\\n3. Receives responses\n",
      "  Backend -left-> DB : 4. Retrieves documents\\n& stores chat history\n",
      "  Backend -right-> LLM : 5. Calls for response\\ngeneration\n",
      "}\n",
      "\n",
      "@enduml\n",
      "✅ Diagram rendered and saved to: artifacts/component_diagram.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ARCHITECTURAL DOCUMENT & DIAGRAM\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4.1\")\n",
    "from utils import render_plantuml_diagram, load_artifact, clean_llm_output\n",
    "\n",
    "component_diagram_prompt = \"\"\"\n",
    "You are an expert system architect. Generate PlantUML code for a component diagram illustrating \n",
    "the architecture of a web-based RAG-Powered Documentation Chatbot.\n",
    "\n",
    "Components:\n",
    "\n",
    "1. User Interface (UI): The web front-end where users interact with the chatbot.\n",
    "\n",
    "2. Backend Service (API Server): Handles requests from the UI, processes queries, and coordinates retrieval and response generation.\n",
    "\n",
    "3. Database or Document Store: Stores the knowledge base (e.g., CUDA documentation) and chat history.\n",
    "\n",
    "4. Language Model (LLM): Uses a language model to generate responses based on the retrieved information.\n",
    "\n",
    "Relationships:\n",
    "1. The User Interface (UI) sends user queries to the Backend Service.\n",
    "2. The Backend Service receives queries, interacts with the Database/Document Store to retrieve relevant information, and calls the language model for response generation.\n",
    "3. The Backend Service returns the generated response to the UI for display to the user.\n",
    "4. The Database/Document Store is accessed by the Backend Service for storing chat history, retrieving documents, and managing knowledge sources.\n",
    "5. The Language Model (LLM) is accessed by the Backend Service for response generation.\n",
    "\n",
    "Output only the raw PlantUML code inside a markdown block.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Component Diagram ---\")\n",
    "component_puml_raw = get_completion(component_diagram_prompt, client, model_name, api_provider)\n",
    "component_puml = clean_llm_output(component_puml_raw, language='plantuml')\n",
    "\n",
    "print(\"\\n--- Generated PlantUML Code ---\")\n",
    "print(component_puml)\n",
    "\n",
    "# Render the diagram\n",
    "\n",
    "if component_puml:\n",
    "    render_plantuml_diagram(component_puml, \"artifacts/component_diagram.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23241c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LLM Client configured: Using 'gemini' with model 'gemini-2.5-pro'\n",
      "--- Generating ADR Template ---\n",
      "```markdown\n",
      "# [ADR Number]. [Title of Decision]\n",
      "\n",
      "## Status\n",
      "\n",
      "[Proposed | Accepted | Deprecated | Superseded]\n",
      "\n",
      "## Context\n",
      "\n",
      "[Describe the context and problem statement that led to this decision. This should include the forces at play, constraints, and assumptions. What is the issue that we're seeing that is motivating this decision or change?]\n",
      "\n",
      "## Decision\n",
      "\n",
      "[State the decision that was made. This should be a clear and concise statement of the change being made. For example, \"We will use a PostgreSQL database for our primary data store.\"]\n",
      "\n",
      "## Consequences\n",
      "\n",
      "[Describe the consequences of this decision, both positive and negative. This includes trade-offs, impact on other parts of the system, performance implications, and any follow-up work required. What becomes easier or harder to do because of this change?]\n",
      "```\n",
      "✅ Successfully saved artifact to: templates/adr_template.md\n",
      "--- Researching Database Options ---\n",
      "| Feature | Using SQLite (with a vector search extension, e.g., sqlite-vss) | Using FAISS |\n",
      "| :--- | :--- | :--- |\n",
      "| **Primary Function** | General-purpose, self-contained relational database (SQL DB). | Specialized library for vector similarity search. |\n",
      "| **Data Storage** | Stores vectors, original text chunks, and metadata (e.g., page number, chapter) together in a single, structured database file. | Stores only the vector index and integer IDs. Requires a separate database or key-value store to map IDs back to text and metadata. |\n",
      "| **Architectural Simplicity** | **High.** A single component manages all data, simplifying development, deployment, and data management. | **Low.** Requires managing two distinct systems: the FAISS index and a separate metadata store, which must be kept synchronized. |\n",
      "| **Vector Search Performance** | **Good.** Sufficient for datasets up to millions of vectors. Slower than FAISS for pure vector search operations. | **State-of-the-Art.** Extremely fast and memory-efficient, especially for large-scale datasets. Offers numerous advanced indexing algorithms. |\n",
      "| **Indexing Options** | **Limited.** Typically offers IVF (Inverted File) and HNSW via extensions. Fewer tuning parameters compared to FAISS. | **Extensive.** Wide variety of index types (e.g., Flat, IVFPQ, HNSW) allowing fine-tuned trade-offs between speed, memory, and accuracy. |\n",
      "| **Ease of Use** | **High.** Uses a familiar SQL interface for all data querying, including vector search. Simple to get started. | **Moderate.** Requires using the FAISS library API. Involves managing the index lifecycle (building, loading, saving) and application-level logic for metadata retrieval. |\n",
      "| **Persistence & Durability** | **High.** Provides full ACID transactional guarantees. Data is durably written to a file. | **Manual.** The index is an in-memory object. It must be explicitly saved to disk to be persisted. No built-in transactional guarantees. |\n",
      "| **Hardware Acceleration** | **CPU-only.** Vector search extensions for SQLite typically do not leverage GPUs. | **CPU and GPU.** FAISS has excellent support for GPU acceleration, which can speed up searches by an order of magnitude or more. |\n",
      "| **Deployment Model** | **Simple.** A single database file is embedded within the application. No separate server process is needed. | **Complex.** The FAISS index must be loaded into the application's memory. A separate metadata store might be a file, or another database server. |\n",
      "| **Overall System Latency** | **Potentially Lower.** A single query can retrieve both the relevant vectors and the associated text/metadata in one disk I/O operation. | **Potentially Higher.** Requires two lookups: one fast in-memory search in FAISS, followed by a second lookup (potentially over a network) to the metadata store. |\n",
      "--- Synthesizing Final ADR ---\n",
      "# ADR-001. Unified Vector and Metadata Storage\n",
      "\n",
      "## Status\n",
      "\n",
      "Accepted\n",
      "\n",
      "## Context\n",
      "\n",
      "Our system is introducing a Retrieval-Augmented Generation (RAG) capability. This feature requires storing and querying three types of related data: 1) semantic vector embeddings, 2) the original text chunks they represent, and 3) associated metadata (e.g., document source, page numbers, timestamps). The core problem is choosing an architecture for storing this data that allows for efficient vector similarity search while maintaining data integrity and operational simplicity.\n",
      "\n",
      "We considered two primary architectural patterns:\n",
      "1.  A specialized vector search library (like FAISS) for the embeddings, coupled with a separate relational database or key-value store for the text and metadata.\n",
      "2.  A single, general-purpose database that can handle both relational data and vector search (like SQLite with a vector search extension).\n",
      "\n",
      "The key forces at play are the need for low-latency retrieval, data consistency between vectors and metadata, development velocity, and operational overhead. Our current scale is in the hundreds of thousands of vectors, and we project growth into the low millions within the next year. Our team has strong SQL expertise, and our current infrastructure for this service is CPU-based.\n",
      "\n",
      "## Decision\n",
      "\n",
      "We will use SQLite, augmented with a vector search extension (e.g., `sqlite-vss`), as the single, unified datastore for vector embeddings, their corresponding text chunks, and all associated metadata.\n",
      "\n",
      "## Consequences\n",
      "\n",
      "### Positive\n",
      "\n",
      "*   **Architectural Simplicity:** We will manage a single system component (an SQLite database file) instead of two separate systems (a vector index and a metadata store). This significantly reduces deployment complexity, operational overhead, and eliminates the need for synchronization logic.\n",
      "*   **Enhanced Data Integrity:** By storing vectors and metadata in the same transactional, ACID-compliant database, we eliminate the risk of data drift or inconsistency where the vector index and metadata store fall out of sync.\n",
      "*   **Improved Development Velocity:** The team can leverage a familiar SQL interface for all data manipulation, including complex queries that filter by metadata and perform vector searches in a single operation. This reduces the learning curve associated with a specialized vector library API.\n",
      "*   **Potentially Lower Overall Latency:** A single query can retrieve the most similar vectors *and* their associated text/metadata in one I/O operation. This avoids the \"two-hop\" problem of querying a vector index for IDs and then making a second query to a separate database to retrieve the actual content.\n",
      "\n",
      "### Negative\n",
      "\n",
      "*   **Reduced Raw Vector Search Performance:** For pure vector search operations on very large datasets, SQLite extensions are not as fast as a highly optimized, in-memory library like FAISS. This is an acceptable trade-off given our current scale (sub-10-million vectors), where the simplicity and data integrity benefits outweigh the need for state-of-the-art speed.\n",
      "*   **Limited Hardware Acceleration:** We forgo the ability to use GPUs for search acceleration, which FAISS supports. This is acceptable as our service is currently deployed on CPU-only infrastructure.\n",
      "*   **Fewer Advanced Indexing Options:** We have access to a more limited set of vector index types (e.g., IVF, HNSW) and fewer tuning parameters compared to FAISS. This restricts our ability to make fine-grained trade-offs between search speed, memory usage, and accuracy.\n",
      "*   **Future Scaling Constraints:** If our dataset grows into the tens or hundreds of millions of vectors, or if vector search becomes the primary system bottleneck, this decision will need to be revisited. At that point, we would need to plan a migration to a more specialized, distributed vector database, and this ADR would be superseded.\n",
      "✅ Successfully saved artifact to: artifacts/adr.md\n"
     ]
    }
   ],
   "source": [
    "# ADR\n",
    "\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gemini-2.5-pro\")\n",
    "\n",
    "adr_template_prompt = \"\"\" You are an expert in software architecture and design. \n",
    "Create a markdown template for an Architectural Decision Record (ADR) in markdown format.\n",
    "The template should include the following sections:\n",
    "Title: A concise title for the decision.\n",
    "Status: The status of the decision (e.g., Proposed, Accepted, Deprecated).\n",
    "Context: The context or background that led to this decision.\n",
    "Decision: The actual decision that was made.\n",
    "Consequences: The consequences or implications of the decision.\n",
    "\n",
    "Output should only be the markdown template without any additional text or explanations.\"\"\"\n",
    "\n",
    "print(\"--- Generating ADR Template ---\")\n",
    "adr_template_content = get_completion(adr_template_prompt, client, model_name, api_provider)\n",
    "print(adr_template_content)\n",
    "\n",
    "# Save the artifact\n",
    "if adr_template_content:\n",
    "    save_artifact(adr_template_content, \"templates/adr_template.md\")\n",
    "\n",
    "db_research_prompt = \"\"\" Act as an unbiased expert in database systems. We are building a web-based RAG-Powered Documentation Chatbot that will use a vector database to store and retrieve information from the CUDA C++ Programming Guide.\n",
    "Use this PRD as context:\n",
    "{simple_prd_output}\n",
    "\n",
    "Objectively compare and contrast two technical options: **\"Using SQLite \"** versus **\"Using FAISS\"**.\n",
    "Output should only include the comparison and not include any additional text or explanations.\"\"\"\n",
    "\n",
    "print(\"--- Researching Database Options ---\")\n",
    "db_research_output = get_completion(db_research_prompt, client, model_name, api_provider)\n",
    "print(db_research_output)\n",
    "\n",
    "adr_template = load_artifact(\"templates/adr_template.md\")\n",
    "\n",
    "# TODO: Write a prompt to synthesize the final ADR.\n",
    "synthesis_prompt = f\"\"\"\n",
    "You are a Staff Engineer and an expert in software architecture and design.\n",
    "Using the following ADR template:\n",
    "\n",
    "{adr_template}\n",
    "\n",
    "And the research findings:\n",
    "\n",
    "{db_research_output}\n",
    "\n",
    "Synthesize the final ADR. Make sure to document the decision-making process clearly, including the context, decision, and consequences.\n",
    "Ensure that the ADR is well-structured and follows best practices for documenting architectural decisions.\n",
    "Output should only include the comparison and not include any additional text or explanations.\"\"\"\n",
    "\n",
    "\n",
    "print(\"--- Synthesizing Final ADR ---\")\n",
    "if adr_template and 'db_research_output' in locals() and db_research_output:\n",
    "    final_adr = get_completion(synthesis_prompt, client, model_name, api_provider)\n",
    "    print(final_adr)\n",
    "    save_artifact(final_adr, \"artifacts/adr.md\")\n",
    "else:\n",
    "    print(\"Skipping ADR synthesis because template or research is missing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d894228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LLM Client configured: Using 'openai' with model 'gpt-4o'\n",
      "--- Generating SQL Schema ---\n",
      "CREATE TABLE Users (\n",
      "    user_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    user_role TEXT NOT NULL CHECK(user_role IN ('New Developer', 'Developer', 'Experienced Developer'))\n",
      ");\n",
      "\n",
      "CREATE TABLE Queries (\n",
      "    query_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    user_id INTEGER NOT NULL,\n",
      "    query_text TEXT NOT NULL,\n",
      "    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
      "    FOREIGN KEY (user_id) REFERENCES Users(user_id)\n",
      ");\n",
      "\n",
      "CREATE TABLE Documents (\n",
      "    document_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    title TEXT NOT NULL,\n",
      "    content TEXT NOT NULL,\n",
      "    version TEXT NOT NULL,\n",
      "    last_updated DATETIME DEFAULT CURRENT_TIMESTAMP\n",
      ");\n",
      "\n",
      "CREATE TABLE Responses (\n",
      "    response_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    query_id INTEGER NOT NULL,\n",
      "    response_text TEXT NOT NULL,\n",
      "    rating INTEGER CHECK(rating BETWEEN 1 AND 5),\n",
      "    FOREIGN KEY (query_id) REFERENCES Queries(query_id)\n",
      ");\n",
      "✅ Successfully saved artifact to: artifacts/schema.sql\n"
     ]
    }
   ],
   "source": [
    "# SCHEMA GENERATION\n",
    "from utils import render_plantuml_diagram, load_artifact, clean_llm_output\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4o\")\n",
    "\n",
    "prd_content = load_artifact(\"artifacts/prd.md\")\n",
    "\n",
    "schema_prompt = f\"\"\"\n",
    "You are an expert Database Administrator (DBA).\n",
    "\n",
    "Based on the following Product Requirements Document (PRD), design a normalized SQL schema for a SQLite database.\n",
    "The schema should include at most 4 tables for minimum viable product.\n",
    "\n",
    "**PRD Context:**\n",
    "<prd>\n",
    "{prd_content}\n",
    "</prd>\n",
    "\n",
    "Output only the raw SQL `CREATE TABLE` statements.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating SQL Schema ---\")\n",
    "if prd_content:\n",
    "    generated_schema = get_completion(schema_prompt, client, model_name, api_provider)\n",
    "    \n",
    "    # Clean up the generated schema\n",
    "    cleaned_schema = clean_llm_output(generated_schema, language='sql')\n",
    "    print(cleaned_schema)\n",
    "    \n",
    "    # Save the cleaned schema to a file\n",
    "    save_artifact(cleaned_schema, \"artifacts/schema.sql\")\n",
    "else:\n",
    "    print(\"Skipping schema generation because PRD is missing.\")\n",
    "    cleaned_schema = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9523b776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LLM Client configured: Using 'openai' with model 'gpt-4o'\n",
      "--- Generating Code ---\n",
      "\n",
      "--- Generated Code ---\n",
      "```python\n",
      "# Pydantic Models\n",
      "from pydantic import BaseModel, Field\n",
      "from datetime import datetime\n",
      "from typing import Optional\n",
      "\n",
      "class UserBase(BaseModel):\n",
      "    user_role: str = Field(..., regex=\"^(New Developer|Developer|Experienced Developer)$\")\n",
      "\n",
      "class UserCreate(UserBase):\n",
      "    pass\n",
      "\n",
      "class User(UserBase):\n",
      "    user_id: int\n",
      "\n",
      "    class Config:\n",
      "        orm_mode = True\n",
      "\n",
      "class QueryBase(BaseModel):\n",
      "    user_id: int\n",
      "    query_text: str\n",
      "\n",
      "class QueryCreate(QueryBase):\n",
      "    pass\n",
      "\n",
      "class Query(QueryBase):\n",
      "    query_id: int\n",
      "    timestamp: datetime\n",
      "\n",
      "    class Config:\n",
      "        orm_mode = True\n",
      "\n",
      "class DocumentBase(BaseModel):\n",
      "    title: str\n",
      "    content: str\n",
      "    version: str\n",
      "\n",
      "class DocumentCreate(DocumentBase):\n",
      "    pass\n",
      "\n",
      "class Document(DocumentBase):\n",
      "    document_id: int\n",
      "    last_updated: datetime\n",
      "\n",
      "    class Config:\n",
      "        orm_mode = True\n",
      "\n",
      "class ResponseBase(BaseModel):\n",
      "    query_id: int\n",
      "    response_text: str\n",
      "    rating: Optional[int] = Field(None, ge=1, le=5)\n",
      "\n",
      "class ResponseCreate(ResponseBase):\n",
      "    pass\n",
      "\n",
      "class Response(ResponseBase):\n",
      "    response_id: int\n",
      "\n",
      "    class Config:\n",
      "        orm_mode = True\n",
      "```\n",
      "\n",
      "```python\n",
      "# SQLAlchemy Models\n",
      "from sqlalchemy import Column, Integer, String, ForeignKey, DateTime, Text, CheckConstraint\n",
      "from sqlalchemy.ext.declarative import declarative_base\n",
      "from sqlalchemy.orm import relationship\n",
      "from datetime import datetime\n",
      "\n",
      "Base = declarative_base()\n",
      "\n",
      "class User(Base):\n",
      "    __tablename__ = 'Users'\n",
      "\n",
      "    user_id = Column(Integer, primary_key=True, autoincrement=True)\n",
      "    user_role = Column(String, nullable=False, check=CheckConstraint(\"user_role IN ('New Developer', 'Developer', 'Experienced Developer')\"))\n",
      "\n",
      "    queries = relationship('Query', back_populates='user')\n",
      "\n",
      "class Query(Base):\n",
      "    __tablename__ = 'Queries'\n",
      "\n",
      "    query_id = Column(Integer, primary_key=True, autoincrement=True)\n",
      "    user_id = Column(Integer, ForeignKey('Users.user_id'), nullable=False)\n",
      "    query_text = Column(Text, nullable=False)\n",
      "    timestamp = Column(DateTime, default=datetime.utcnow)\n",
      "\n",
      "    user = relationship('User', back_populates='queries')\n",
      "    responses = relationship('Response', back_populates='query')\n",
      "\n",
      "class Document(Base):\n",
      "    __tablename__ = 'Documents'\n",
      "\n",
      "    document_id = Column(Integer, primary_key=True, autoincrement=True)\n",
      "    title = Column(String, nullable=False)\n",
      "    content = Column(Text, nullable=False)\n",
      "    version = Column(String, nullable=False)\n",
      "    last_updated = Column(DateTime, default=datetime.utcnow)\n",
      "\n",
      "class Response(Base):\n",
      "    __tablename__ = 'Responses'\n",
      "\n",
      "    response_id = Column(Integer, primary_key=True, autoincrement=True)\n",
      "    query_id = Column(Integer, ForeignKey('Queries.query_id'), nullable=False)\n",
      "    response_text = Column(Text, nullable=False)\n",
      "    rating = Column(Integer, check=CheckConstraint('rating BETWEEN 1 AND 5'))\n",
      "\n",
      "    query = relationship('Query', back_populates='responses')\n",
      "```\n",
      "\n",
      "```python\n",
      "# FastAPI Application\n",
      "from fastapi import FastAPI, HTTPException, Depends\n",
      "from sqlalchemy.orm import Session\n",
      "from fastapi import status\n",
      "from fastapi.middleware.cors import CORSMiddleware\n",
      "from typing import List\n",
      "from database import SessionLocal, engine\n",
      "from models import Base, User, Query, Document, Response\n",
      "from schemas import UserCreate, User, QueryCreate, Query, DocumentCreate, Document, ResponseCreate, Response\n",
      "\n",
      "Base.metadata.create_all(bind=engine)\n",
      "\n",
      "app = FastAPI()\n",
      "\n",
      "app.add_middleware(\n",
      "    CORSMiddleware,\n",
      "    allow_origins=[\"*\"],\n",
      "    allow_credentials=True,\n",
      "    allow_methods=[\"*\"],\n",
      "    allow_headers=[\"*\"],\n",
      ")\n",
      "\n",
      "def get_db():\n",
      "    db = SessionLocal()\n",
      "    try:\n",
      "        yield db\n",
      "    finally:\n",
      "        db.close()\n",
      "\n",
      "# CRUD Operations for Users\n",
      "@app.post(\"/users/\", response_model=User, status_code=status.HTTP_201_CREATED)\n",
      "def create_user(user: UserCreate, db: Session = Depends(get_db)):\n",
      "    db_user = User(**user.dict())\n",
      "    db.add(db_user)\n",
      "    db.commit()\n",
      "    db.refresh(db_user)\n",
      "    return db_user\n",
      "\n",
      "@app.get(\"/users/{user_id}\", response_model=User)\n",
      "def read_user(user_id: int, db: Session = Depends(get_db)):\n",
      "    db_user = db.query(User).filter(User.user_id == user_id).first()\n",
      "    if db_user is None:\n",
      "        raise HTTPException(status_code=404, detail=\"User not found\")\n",
      "    return db_user\n",
      "\n",
      "@app.put(\"/users/{user_id}\", response_model=User)\n",
      "def update_user(user_id: int, user: UserCreate, db: Session = Depends(get_db)):\n",
      "    db_user = db.query(User).filter(User.user_id == user_id).first()\n",
      "    if db_user is None:\n",
      "        raise HTTPException(status_code=404, detail=\"User not found\")\n",
      "    for key, value in user.dict().items():\n",
      "        setattr(db_user, key, value)\n",
      "    db.commit()\n",
      "    db.refresh(db_user)\n",
      "    return db_user\n",
      "\n",
      "@app.delete(\"/users/{user_id}\", status_code=status.HTTP_204_NO_CONTENT)\n",
      "def delete_user(user_id: int, db: Session = Depends(get_db)):\n",
      "    db_user = db.query(User).filter(User.user_id == user_id).first()\n",
      "    if db_user is None:\n",
      "        raise HTTPException(status_code=404, detail=\"User not found\")\n",
      "    db.delete(db_user)\n",
      "    db.commit()\n",
      "    return\n",
      "\n",
      "# CRUD Operations for Queries\n",
      "@app.post(\"/queries/\", response_model=Query, status_code=status.HTTP_201_CREATED)\n",
      "def create_query(query: QueryCreate, db: Session = Depends(get_db)):\n",
      "    db_query = Query(**query.dict())\n",
      "    db.add(db_query)\n",
      "    db.commit()\n",
      "    db.refresh(db_query)\n",
      "    return db_query\n",
      "\n",
      "@app.get(\"/queries/{query_id}\", response_model=Query)\n",
      "def read_query(query_id: int, db: Session = Depends(get_db)):\n",
      "    db_query = db.query(Query).filter(Query.query_id == query_id).first()\n",
      "    if db_query is None:\n",
      "        raise HTTPException(status_code=404, detail=\"Query not found\")\n",
      "    return db_query\n",
      "\n",
      "@app.put(\"/queries/{query_id}\", response_model=Query)\n",
      "def update_query(query_id: int, query: QueryCreate, db: Session = Depends(get_db)):\n",
      "    db_query = db.query(Query).filter(Query.query_id == query_id).first()\n",
      "    if db_query is None:\n",
      "        raise HTTPException(status_code=404, detail=\"Query not found\")\n",
      "    for key, value in query.dict().items():\n",
      "        setattr(db_query, key, value)\n",
      "    db.commit()\n",
      "    db.refresh(db_query)\n",
      "    return db_query\n",
      "\n",
      "@app.delete(\"/queries/{query_id}\", status_code=status.HTTP_204_NO_CONTENT)\n",
      "def delete_query(query_id: int, db: Session = Depends(get_db)):\n",
      "    db_query = db.query(Query).filter(Query.query_id == query_id).first()\n",
      "    if db_query is None:\n",
      "        raise HTTPException(status_code=404, detail=\"Query not found\")\n",
      "    db.delete(db_query)\n",
      "    db.commit()\n",
      "    return\n",
      "\n",
      "# CRUD Operations for Documents\n",
      "@app.post(\"/documents/\", response_model=Document, status_code=status.HTTP_201_CREATED)\n",
      "def create_document(document: DocumentCreate, db: Session = Depends(get_db)):\n",
      "    db_document = Document(**document.dict())\n",
      "    db.add(db_document)\n",
      "    db.commit()\n",
      "    db.refresh(db_document)\n",
      "    return db_document\n",
      "\n",
      "@app.get(\"/documents/{document_id}\", response_model=Document)\n",
      "def read_document(document_id: int, db: Session = Depends(get_db)):\n",
      "    db_document = db.query(Document).filter(Document.document_id == document_id).first()\n",
      "    if db_document is None:\n",
      "        raise HTTPException(status_code=404, detail=\"Document not found\")\n",
      "    return db_document\n",
      "\n",
      "@app.put(\"/documents/{document_id}\", response_model=Document)\n",
      "def update_document(document_id: int, document: DocumentCreate, db: Session = Depends(get_db)):\n",
      "    db_document = db.query(Document).filter(Document.document_id == document_id).first()\n",
      "    if db_document is None:\n",
      "        raise HTTPException(status_code=404, detail=\"Document not found\")\n",
      "    for key, value in document.dict().items():\n",
      "        setattr(db_document, key, value)\n",
      "    db.commit()\n",
      "    db.refresh(db_document)\n",
      "    return db_document\n",
      "\n",
      "@app.delete(\"/documents/{document_id}\", status_code=status.HTTP_204_NO_CONTENT)\n",
      "def delete_document(document_id: int, db: Session = Depends(get_db)):\n",
      "    db_document = db.query(Document).filter(Document.document_id == document_id).first()\n",
      "    if db_document is None:\n",
      "        raise HTTPException(status_code=404, detail=\"Document not found\")\n",
      "    db.delete(db_document)\n",
      "    db.commit()\n",
      "    return\n",
      "\n",
      "# CRUD Operations for Responses\n",
      "@app.post(\"/responses/\", response_model=Response, status_code=status.HTTP_201_CREATED)\n",
      "def create_response(response: ResponseCreate, db: Session = Depends(get_db)):\n",
      "    db_response = Response(**response.dict())\n",
      "    db.add(db_response)\n",
      "    db.commit()\n",
      "    db.refresh(db_response)\n",
      "    return db_response\n",
      "\n",
      "@app.get(\"/responses/{response_id}\", response_model=Response)\n",
      "def read_response(response_id: int, db: Session = Depends(get_db)):\n",
      "    db_response = db.query(Response).filter(Response.response_id == response_id).first()\n",
      "    if db_response is None:\n",
      "        raise HTTPException(status_code=404, detail=\"Response not found\")\n",
      "    return db_response\n",
      "\n",
      "@app.put(\"/responses/{response_id}\", response_model=Response)\n",
      "def update_response(response_id: int, response: ResponseCreate, db: Session = Depends(get_db)):\n",
      "    db_response = db.query(Response).filter(Response.response_id == response_id).first()\n",
      "    if db_response is None:\n",
      "        raise HTTPException(status_code=404, detail=\"Response not found\")\n",
      "    for key, value in response.dict().items():\n",
      "        setattr(db_response, key, value)\n",
      "    db.commit()\n",
      "    db.refresh(db_response)\n",
      "    return db_response\n",
      "\n",
      "@app.delete(\"/responses/{response_id}\", status_code=status.HTTP_204_NO_CONTENT)\n",
      "def delete_response(response_id: int, db: Session = Depends(get_db)):\n",
      "    db_response = db.query(Response).filter(Response.response_id == response_id).first()\n",
      "    if db_response is None:\n",
      "        raise HTTPException(status_code=404, detail=\"Response not found\")\n",
      "    db.delete(db_response)\n",
      "    db.commit()\n",
      "    return\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# BACKEND CODE GENERATION\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, load_artifact, clean_llm_output\n",
    "\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4o\")\n",
    "\n",
    "\n",
    "sql_schema = load_artifact(\"artifacts/schema.sql\")\n",
    "if not sql_schema:\n",
    "    print(\"Warning: Could not load schema.sql. Lab may not function correctly.\")\n",
    "\n",
    "code_prompt = f\"\"\"\n",
    "You are a Python expert specializing in FastAPI and SQLAlchemy.\n",
    "\n",
    "Based on the provided SQL schema\n",
    "\n",
    "**SQL Schema Context:**\n",
    "```sql\n",
    "{sql_schema}\n",
    "```\n",
    "\n",
    "Please provide three separate, well-commented code blocks:\n",
    "\n",
    "1.  **Pydantic Models:** Create the Pydantic models for the tables.\n",
    "2.  **SQLAlchemy Models:** Create the SQLAlchemy models for the tables.\n",
    "3.  **FastAPI Application:** Generate the simple FastAPI application with full CRUD endpoints for the models.\n",
    "\n",
    "Only output the raw Python code.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Code ---\")\n",
    "if sql_schema:\n",
    "    generated_code = get_completion(code_prompt, client, model_name, api_provider)\n",
    "    print(\"\\n--- Generated Code ---\")\n",
    "    print(generated_code)\n",
    "else:\n",
    "    print(\"Skipping DB code generation because schema is missing.\")\n",
    "\n",
    "#PROMPTED TO GENERATE BACKEND CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4667b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LLM Client configured: Using 'openai' with model 'gpt-4o'\n",
      "--- Generating Happy Path Tests ---\n",
      "import pytest\n",
      "from fastapi.testclient import TestClient\n",
      "from main import app\n",
      "\n",
      "client = TestClient(app)\n",
      "\n",
      "def test_create_document():\n",
      "    # Given\n",
      "    document_data = {\n",
      "        \"title\": \"CUDA Programming Guide\",\n",
      "        \"content\": \"This is a guide to CUDA programming.\",\n",
      "        \"source_url\": \"http://example.com/cuda-guide\"\n",
      "    }\n",
      "\n",
      "    # When\n",
      "    response = client.post(\"/api/v1/documents/upload\", json=document_data)\n",
      "\n",
      "    # Then\n",
      "    assert response.status_code == 200\n",
      "    response_data = response.json()\n",
      "    assert response_data[\"title\"] == document_data[\"title\"]\n",
      "\n",
      "def test_read_documents():\n",
      "    # First create a document\n",
      "    document_data = {\n",
      "        \"title\": \"CUDA Programming Guide\",\n",
      "        \"content\": \"This is a guide to CUDA programming.\",\n",
      "        \"source_url\": \"http://example.com/cuda-guide\"\n",
      "    }\n",
      "    client.post(\"/api/v1/documents/upload\", json=document_data)\n",
      "\n",
      "    # When\n",
      "    response = client.get(\"/api/v1/documents/\")\n",
      "\n",
      "    # Then\n",
      "    assert response.status_code == 200\n",
      "    response_data = response.json()\n",
      "    assert isinstance(response_data, list)\n",
      "    assert len(response_data) > 0\n",
      "\n",
      "def test_create_chat_history():\n",
      "    # Given\n",
      "    chat_history_data = {\n",
      "        \"user_id\": 1,\n",
      "        \"query\": \"What is CUDA?\",\n",
      "    }\n",
      "\n",
      "    # When\n",
      "    response = client.post(\"/api/v1/chat/ask\", json=chat_history_data)\n",
      "\n",
      "    # Then\n",
      "    assert response.status_code == 200\n",
      "    response_data = response.json()\n",
      "    assert response_data[\"query\"] == chat_history_data[\"query\"]\n",
      "\n",
      "def test_read_chat_history():\n",
      "    # First create a chat history\n",
      "    chat_history_data = {\n",
      "        \"user_id\": 1,\n",
      "        \"query\": \"What is CUDA?\",\n",
      "    }\n",
      "    client.post(\"/api/v1/chat/ask\", json=chat_history_data)\n",
      "\n",
      "    # When\n",
      "    response = client.get(\"/api/v1/chat_history/\")\n",
      "\n",
      "    # Then\n",
      "    assert response.status_code == 200\n",
      "    response_data = response.json()\n",
      "    assert isinstance(response_data, list)\n",
      "    assert len(response_data) > 0\n",
      "✅ Successfully saved artifact to: tests/happy_path_tests.py\n",
      "--- Generating Edge Case Tests ---\n",
      "from fastapi.testclient import TestClient\n",
      "from main import app\n",
      "\n",
      "client = TestClient(app)\n",
      "\n",
      "def test_read_document_not_found():\n",
      "    response = client.get(\"/api/v1/documents/999\")\n",
      "    assert response.status_code == 404\n",
      "    assert response.json() == {\"detail\": \"Document not found\"}\n",
      "\n",
      "def test_read_chat_history_not_found():\n",
      "    response = client.get(\"/api/v1/chat/history/999\")\n",
      "    assert response.status_code == 404\n",
      "    assert response.json() == {\"detail\": \"Chat history not found\"}\n",
      "✅ Successfully saved artifact to: tests/edge_case_tests.py\n"
     ]
    }
   ],
   "source": [
    "# CREATE TESTS\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, load_artifact, clean_llm_output\n",
    "\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4o\")\n",
    "\n",
    "# Load the application code to provide context for test generation\n",
    "app_code = load_artifact(\"main.py\")\n",
    "if not app_code:\n",
    "    print(\"Warning: Could not load main.py. Lab may not function correctly.\")\n",
    "\n",
    "happy_path_tests_prompt = f\"\"\"\n",
    "You are a Senior QA Engineer writing tests for a FastAPI application using pytest.\n",
    "\n",
    "Based on the application code provided below, please generate two 'happy path' test functions in a single Python script:\n",
    "1. A test named `test_create_document` for the `POST /documents/` endpoint. It should create a document and assert that the status code is 200 and the response title matches the input.\n",
    "2. A test named `test_read_documents` for the `GET /documents/` endpoint. It should first create a document and then assert the status code is 200 and that the response is a list containing at least one document.\n",
    "3. A test named `test_create_chat_history` for the `POST /chat_history/` endpoint. It should create a chat history and assert that the status code is 200 and the response query matches the input.\n",
    "4. A test named `test_read_chat_history` for the `GET /chat_history/` endpoint. It should first create a chat history and then assert the status code is 200 and that the response is a list containing at least one chat history.\n",
    "\n",
    "**Application Code Context:**\n",
    "```python\n",
    "{app_code}\n",
    "```\n",
    "\n",
    "Your response should be only the raw Python code for the tests.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Happy Path Tests ---\")\n",
    "if app_code:\n",
    "    generated_happy_path_tests = get_completion(happy_path_tests_prompt, client, model_name, api_provider)\n",
    "    cleaned_tests = clean_llm_output(generated_happy_path_tests, language='python')\n",
    "    print(cleaned_tests)\n",
    "    save_artifact(cleaned_tests, \"tests/happy_path_tests.py\")\n",
    "else:\n",
    "    print(\"Skipping test generation because app code is missing.\")\n",
    "\n",
    "edge_case_tests_prompt = f\"\"\"\n",
    "You are a QA Engineer focused on identifying edge cases.\n",
    "\n",
    "Based on the FastAPI application code provided, write two test functions for common error scenarios:\n",
    "1.  A test named `test_read_document_not_found` that attempts to GET a document with an ID that does not exist (e.g., 999). It must assert that the API returns a 404 status code.\n",
    "2.  A test named `test_read_chat_history_not_found` that attempts to GET a chat history with an ID that does not exist (e.g., 999). It must assert that the API returns a 404 status code.\n",
    "\n",
    "**Application Code Context:**\n",
    "```python\n",
    "{app_code}\n",
    "```\n",
    "\n",
    "Output only the raw Python code for the tests.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Edge Case Tests ---\")\n",
    "if app_code:\n",
    "    generated_edge_case_tests = get_completion(edge_case_tests_prompt, client, model_name, api_provider)\n",
    "    cleaned_edge_case_tests = clean_llm_output(generated_edge_case_tests, language='python')\n",
    "    print(cleaned_edge_case_tests)  \n",
    "    save_artifact(cleaned_edge_case_tests, \"tests/edge_case_tests.py\")\n",
    "else:\n",
    "    print(\"Skipping test generation because app code is missing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "209c2a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LLM Client configured: Using 'openai' with model 'gpt-4o'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ibb.co/gFb08jXz/screenshot.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Monolithic UI Component ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #F00 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #04D } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #00F; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #800 } /* Name.Constant */\n",
       ".output_html .nd { color: #A2F } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #00F } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #00F; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #A2F; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #BBB } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #00F } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"k\">import</span><span class=\"w\"> </span><span class=\"nx\">React</span><span class=\"w\"> </span><span class=\"kr\">from</span><span class=\"w\"> </span><span class=\"s1\">&#39;react&#39;</span><span class=\"p\">;</span>\n",
       "\n",
       "<span class=\"kd\">const</span><span class=\"w\"> </span><span class=\"nx\">CudaChatbot</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"p\">()</span><span class=\"w\"> </span><span class=\"p\">=&gt;</span><span class=\"w\"> </span><span class=\"p\">{</span>\n",
       "<span class=\"w\">  </span><span class=\"k\">return</span><span class=\"w\"> </span><span class=\"p\">(</span>\n",
       "<span class=\"w\">    </span><span class=\"p\">&lt;</span><span class=\"nt\">div</span><span class=\"w\"> </span><span class=\"na\">className</span><span class=\"o\">=</span><span class=\"s\">&quot;flex flex-col items-center justify-center min-h-screen bg-gray-100&quot;</span><span class=\"p\">&gt;</span>\n",
       "<span class=\"w\">      </span><span class=\"p\">&lt;</span><span class=\"nt\">h1</span><span class=\"w\"> </span><span class=\"na\">className</span><span class=\"o\">=</span><span class=\"s\">&quot;text-4xl font-bold text-gray-800 mb-2&quot;</span><span class=\"p\">&gt;</span>\n",
       "<span class=\"w\">        </span><span class=\"nx\">CUDA</span><span class=\"w\"> </span><span class=\"nx\">Documentation</span><span class=\"w\"> </span><span class=\"nx\">Chatbot</span>\n",
       "<span class=\"w\">      </span><span class=\"p\">&lt;/</span><span class=\"nt\">h1</span><span class=\"p\">&gt;</span>\n",
       "<span class=\"w\">      </span><span class=\"p\">&lt;</span><span class=\"nt\">p</span><span class=\"w\"> </span><span class=\"na\">className</span><span class=\"o\">=</span><span class=\"s\">&quot;text-gray-600 mb-6&quot;</span><span class=\"p\">&gt;</span><span class=\"nx\">Ask</span><span class=\"w\"> </span><span class=\"nx\">questions</span><span class=\"w\"> </span><span class=\"nx\">about</span><span class=\"w\"> </span><span class=\"nx\">CUDA</span><span class=\"p\">&lt;/</span><span class=\"nt\">p</span><span class=\"p\">&gt;</span>\n",
       "<span class=\"w\">      </span><span class=\"p\">&lt;</span><span class=\"nt\">div</span><span class=\"w\"> </span><span class=\"na\">className</span><span class=\"o\">=</span><span class=\"s\">&quot;bg-white rounded-lg shadow-lg p-4 max-w-xl w-full&quot;</span><span class=\"p\">&gt;</span>\n",
       "<span class=\"w\">        </span><span class=\"p\">&lt;</span><span class=\"nt\">div</span><span class=\"w\"> </span><span class=\"na\">className</span><span class=\"o\">=</span><span class=\"s\">&quot;bg-gray-200 p-3 rounded-lg text-gray-700 mb-4&quot;</span><span class=\"p\">&gt;</span>\n",
       "<span class=\"w\">          </span><span class=\"nx\">Hello</span><span class=\"o\">!</span><span class=\"w\"> </span><span class=\"nx\">I</span><span class=\"w\"> </span><span class=\"nx\">am</span><span class=\"w\"> </span><span class=\"nx\">your</span><span class=\"w\"> </span><span class=\"nx\">CUDA</span><span class=\"w\"> </span><span class=\"nx\">documentation</span><span class=\"w\"> </span><span class=\"nx\">assistant</span><span class=\"p\">.</span><span class=\"w\"> </span><span class=\"nx\">Ask</span><span class=\"w\"> </span><span class=\"nx\">me</span><span class=\"w\"> </span><span class=\"nx\">anything</span><span class=\"w\"> </span><span class=\"nx\">about</span><span class=\"w\"> </span><span class=\"nx\">CUDA</span><span class=\"w\"> </span><span class=\"nx\">programming</span><span class=\"p\">.</span>\n",
       "<span class=\"w\">        </span><span class=\"p\">&lt;/</span><span class=\"nt\">div</span><span class=\"p\">&gt;</span>\n",
       "<span class=\"w\">        </span><span class=\"p\">&lt;</span><span class=\"nt\">div</span><span class=\"w\"> </span><span class=\"na\">className</span><span class=\"o\">=</span><span class=\"s\">&quot;flex items-center&quot;</span><span class=\"p\">&gt;</span>\n",
       "<span class=\"w\">          </span><span class=\"p\">&lt;</span><span class=\"nt\">input</span>\n",
       "<span class=\"w\">            </span><span class=\"na\">type</span><span class=\"o\">=</span><span class=\"s\">&quot;text&quot;</span>\n",
       "<span class=\"w\">            </span><span class=\"na\">placeholder</span><span class=\"o\">=</span><span class=\"s\">&quot;Type your CUDA question...&quot;</span>\n",
       "<span class=\"w\">            </span><span class=\"na\">className</span><span class=\"o\">=</span><span class=\"s\">&quot;flex-grow p-2 rounded-l-full border border-gray-300 focus:outline-none focus:ring-2 focus:ring-blue-400&quot;</span>\n",
       "<span class=\"w\">          </span><span class=\"p\">/&gt;</span>\n",
       "<span class=\"w\">          </span><span class=\"p\">&lt;</span><span class=\"nt\">button</span><span class=\"w\"> </span><span class=\"na\">className</span><span class=\"o\">=</span><span class=\"s\">&quot;bg-blue-500 text-white p-2 rounded-r-full hover:bg-blue-600 focus:outline-none focus:ring-2 focus:ring-blue-400&quot;</span><span class=\"p\">&gt;</span>\n",
       "<span class=\"w\">            </span><span class=\"nx\">Send</span>\n",
       "<span class=\"w\">          </span><span class=\"p\">&lt;/</span><span class=\"nt\">button</span><span class=\"p\">&gt;</span>\n",
       "<span class=\"w\">        </span><span class=\"p\">&lt;/</span><span class=\"nt\">div</span><span class=\"p\">&gt;</span>\n",
       "<span class=\"w\">      </span><span class=\"p\">&lt;/</span><span class=\"nt\">div</span><span class=\"p\">&gt;</span>\n",
       "<span class=\"w\">    </span><span class=\"p\">&lt;/</span><span class=\"nt\">div</span><span class=\"p\">&gt;</span>\n",
       "<span class=\"w\">  </span><span class=\"p\">);</span>\n",
       "<span class=\"p\">};</span>\n",
       "\n",
       "<span class=\"k\">export</span><span class=\"w\"> </span><span class=\"k\">default</span><span class=\"w\"> </span><span class=\"nx\">CudaChatbot</span><span class=\"p\">;</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k}{import}\\PY{+w}{ }\\PY{n+nx}{React}\\PY{+w}{ }\\PY{k+kr}{from}\\PY{+w}{ }\\PY{l+s+s1}{\\PYZsq{}react\\PYZsq{}}\\PY{p}{;}\n",
       "\n",
       "\\PY{k+kd}{const}\\PY{+w}{ }\\PY{n+nx}{CudaChatbot}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{p}{(}\\PY{p}{)}\\PY{+w}{ }\\PY{p}{=\\PYZgt{}}\\PY{+w}{ }\\PY{p}{\\PYZob{}}\n",
       "\\PY{+w}{  }\\PY{k}{return}\\PY{+w}{ }\\PY{p}{(}\n",
       "\\PY{+w}{    }\\PY{p}{\\PYZlt{}}\\PY{n+nt}{div}\\PY{+w}{ }\\PY{n+na}{className}\\PY{o}{=}\\PY{l+s}{\\PYZdq{}flex flex\\PYZhy{}col items\\PYZhy{}center justify\\PYZhy{}center min\\PYZhy{}h\\PYZhy{}screen bg\\PYZhy{}gray\\PYZhy{}100\\PYZdq{}}\\PY{p}{\\PYZgt{}}\n",
       "\\PY{+w}{      }\\PY{p}{\\PYZlt{}}\\PY{n+nt}{h1}\\PY{+w}{ }\\PY{n+na}{className}\\PY{o}{=}\\PY{l+s}{\\PYZdq{}text\\PYZhy{}4xl font\\PYZhy{}bold text\\PYZhy{}gray\\PYZhy{}800 mb\\PYZhy{}2\\PYZdq{}}\\PY{p}{\\PYZgt{}}\n",
       "\\PY{+w}{        }\\PY{n+nx}{CUDA}\\PY{+w}{ }\\PY{n+nx}{Documentation}\\PY{+w}{ }\\PY{n+nx}{Chatbot}\n",
       "\\PY{+w}{      }\\PY{p}{\\PYZlt{}/}\\PY{n+nt}{h1}\\PY{p}{\\PYZgt{}}\n",
       "\\PY{+w}{      }\\PY{p}{\\PYZlt{}}\\PY{n+nt}{p}\\PY{+w}{ }\\PY{n+na}{className}\\PY{o}{=}\\PY{l+s}{\\PYZdq{}text\\PYZhy{}gray\\PYZhy{}600 mb\\PYZhy{}6\\PYZdq{}}\\PY{p}{\\PYZgt{}}\\PY{n+nx}{Ask}\\PY{+w}{ }\\PY{n+nx}{questions}\\PY{+w}{ }\\PY{n+nx}{about}\\PY{+w}{ }\\PY{n+nx}{CUDA}\\PY{p}{\\PYZlt{}/}\\PY{n+nt}{p}\\PY{p}{\\PYZgt{}}\n",
       "\\PY{+w}{      }\\PY{p}{\\PYZlt{}}\\PY{n+nt}{div}\\PY{+w}{ }\\PY{n+na}{className}\\PY{o}{=}\\PY{l+s}{\\PYZdq{}bg\\PYZhy{}white rounded\\PYZhy{}lg shadow\\PYZhy{}lg p\\PYZhy{}4 max\\PYZhy{}w\\PYZhy{}xl w\\PYZhy{}full\\PYZdq{}}\\PY{p}{\\PYZgt{}}\n",
       "\\PY{+w}{        }\\PY{p}{\\PYZlt{}}\\PY{n+nt}{div}\\PY{+w}{ }\\PY{n+na}{className}\\PY{o}{=}\\PY{l+s}{\\PYZdq{}bg\\PYZhy{}gray\\PYZhy{}200 p\\PYZhy{}3 rounded\\PYZhy{}lg text\\PYZhy{}gray\\PYZhy{}700 mb\\PYZhy{}4\\PYZdq{}}\\PY{p}{\\PYZgt{}}\n",
       "\\PY{+w}{          }\\PY{n+nx}{Hello}\\PY{o}{!}\\PY{+w}{ }\\PY{n+nx}{I}\\PY{+w}{ }\\PY{n+nx}{am}\\PY{+w}{ }\\PY{n+nx}{your}\\PY{+w}{ }\\PY{n+nx}{CUDA}\\PY{+w}{ }\\PY{n+nx}{documentation}\\PY{+w}{ }\\PY{n+nx}{assistant}\\PY{p}{.}\\PY{+w}{ }\\PY{n+nx}{Ask}\\PY{+w}{ }\\PY{n+nx}{me}\\PY{+w}{ }\\PY{n+nx}{anything}\\PY{+w}{ }\\PY{n+nx}{about}\\PY{+w}{ }\\PY{n+nx}{CUDA}\\PY{+w}{ }\\PY{n+nx}{programming}\\PY{p}{.}\n",
       "\\PY{+w}{        }\\PY{p}{\\PYZlt{}/}\\PY{n+nt}{div}\\PY{p}{\\PYZgt{}}\n",
       "\\PY{+w}{        }\\PY{p}{\\PYZlt{}}\\PY{n+nt}{div}\\PY{+w}{ }\\PY{n+na}{className}\\PY{o}{=}\\PY{l+s}{\\PYZdq{}flex items\\PYZhy{}center\\PYZdq{}}\\PY{p}{\\PYZgt{}}\n",
       "\\PY{+w}{          }\\PY{p}{\\PYZlt{}}\\PY{n+nt}{input}\n",
       "\\PY{+w}{            }\\PY{n+na}{type}\\PY{o}{=}\\PY{l+s}{\\PYZdq{}text\\PYZdq{}}\n",
       "\\PY{+w}{            }\\PY{n+na}{placeholder}\\PY{o}{=}\\PY{l+s}{\\PYZdq{}Type your CUDA question...\\PYZdq{}}\n",
       "\\PY{+w}{            }\\PY{n+na}{className}\\PY{o}{=}\\PY{l+s}{\\PYZdq{}flex\\PYZhy{}grow p\\PYZhy{}2 rounded\\PYZhy{}l\\PYZhy{}full border border\\PYZhy{}gray\\PYZhy{}300 focus:outline\\PYZhy{}none focus:ring\\PYZhy{}2 focus:ring\\PYZhy{}blue\\PYZhy{}400\\PYZdq{}}\n",
       "\\PY{+w}{          }\\PY{p}{/}\\PY{p}{\\PYZgt{}}\n",
       "\\PY{+w}{          }\\PY{p}{\\PYZlt{}}\\PY{n+nt}{button}\\PY{+w}{ }\\PY{n+na}{className}\\PY{o}{=}\\PY{l+s}{\\PYZdq{}bg\\PYZhy{}blue\\PYZhy{}500 text\\PYZhy{}white p\\PYZhy{}2 rounded\\PYZhy{}r\\PYZhy{}full hover:bg\\PYZhy{}blue\\PYZhy{}600 focus:outline\\PYZhy{}none focus:ring\\PYZhy{}2 focus:ring\\PYZhy{}blue\\PYZhy{}400\\PYZdq{}}\\PY{p}{\\PYZgt{}}\n",
       "\\PY{+w}{            }\\PY{n+nx}{Send}\n",
       "\\PY{+w}{          }\\PY{p}{\\PYZlt{}/}\\PY{n+nt}{button}\\PY{p}{\\PYZgt{}}\n",
       "\\PY{+w}{        }\\PY{p}{\\PYZlt{}/}\\PY{n+nt}{div}\\PY{p}{\\PYZgt{}}\n",
       "\\PY{+w}{      }\\PY{p}{\\PYZlt{}/}\\PY{n+nt}{div}\\PY{p}{\\PYZgt{}}\n",
       "\\PY{+w}{    }\\PY{p}{\\PYZlt{}/}\\PY{n+nt}{div}\\PY{p}{\\PYZgt{}}\n",
       "\\PY{+w}{  }\\PY{p}{)}\\PY{p}{;}\n",
       "\\PY{p}{\\PYZcb{}}\\PY{p}{;}\n",
       "\n",
       "\\PY{k}{export}\\PY{+w}{ }\\PY{k}{default}\\PY{+w}{ }\\PY{n+nx}{CudaChatbot}\\PY{p}{;}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "import React from 'react';\n",
       "\n",
       "const CudaChatbot = () => {\n",
       "  return (\n",
       "    <div className=\"flex flex-col items-center justify-center min-h-screen bg-gray-100\">\n",
       "      <h1 className=\"text-4xl font-bold text-gray-800 mb-2\">\n",
       "        CUDA Documentation Chatbot\n",
       "      </h1>\n",
       "      <p className=\"text-gray-600 mb-6\">Ask questions about CUDA</p>\n",
       "      <div className=\"bg-white rounded-lg shadow-lg p-4 max-w-xl w-full\">\n",
       "        <div className=\"bg-gray-200 p-3 rounded-lg text-gray-700 mb-4\">\n",
       "          Hello! I am your CUDA documentation assistant. Ask me anything about CUDA programming.\n",
       "        </div>\n",
       "        <div className=\"flex items-center\">\n",
       "          <input\n",
       "            type=\"text\"\n",
       "            placeholder=\"Type your CUDA question...\"\n",
       "            className=\"flex-grow p-2 rounded-l-full border border-gray-300 focus:outline-none focus:ring-2 focus:ring-blue-400\"\n",
       "          />\n",
       "          <button className=\"bg-blue-500 text-white p-2 rounded-r-full hover:bg-blue-600 focus:outline-none focus:ring-2 focus:ring-blue-400\">\n",
       "            Send\n",
       "          </button>\n",
       "        </div>\n",
       "      </div>\n",
       "    </div>\n",
       "  );\n",
       "};\n",
       "\n",
       "export default CudaChatbot;"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully saved artifact to: artifacts/component.jsx\n",
      "--- Generating Frontend Code ---\n",
      "Certainly! Below is a basic example of a React frontend application for a RAG-powered documentation chatbot for CUDA. This example assumes a simple chat interface that connects to a FastAPI backend.\n",
      "\n",
      "```jsx\n",
      "import React, { useState } from 'react';\n",
      "import './App.css';\n",
      "\n",
      "function App() {\n",
      "  const [input, setInput] = useState('');\n",
      "  const [messages, setMessages] = useState([]);\n",
      "\n",
      "  const handleInputChange = (event) => {\n",
      "    setInput(event.target.value);\n",
      "  };\n",
      "\n",
      "  const handleSend = async () => {\n",
      "    if (!input) return;\n",
      "\n",
      "    const userMessage = { sender: 'user', text: input };\n",
      "    setMessages([...messages, userMessage]);\n",
      "\n",
      "    setInput('');\n",
      "\n",
      "    // Send the input to the FastAPI backend\n",
      "    try {\n",
      "      const response = await fetch('http://localhost:8000/chat', {\n",
      "        method: 'POST',\n",
      "        headers: {\n",
      "          'Content-Type': 'application/json',\n",
      "        },\n",
      "        body: JSON.stringify({ message: input }),\n",
      "      });\n",
      "\n",
      "      if (!response.ok) {\n",
      "        throw new Error('Failed to fetch the response');\n",
      "      }\n",
      "\n",
      "      const data = await response.json();\n",
      "      const botMessage = { sender: 'bot', text: data.response };\n",
      "      setMessages((prevMessages) => [...prevMessages, botMessage]);\n",
      "    } catch (error) {\n",
      "      console.error('Error fetching chatbot response:', error);\n",
      "      const errorMessage = { sender: 'bot', text: 'Error fetching response. Please try again later.' };\n",
      "      setMessages((prevMessages) => [...prevMessages, errorMessage]);\n",
      "    }\n",
      "  };\n",
      "\n",
      "  return (\n",
      "    <div className=\"App\">\n",
      "      <h1>CUDA Documentation Chatbot</h1>\n",
      "      <div className=\"chat-window\">\n",
      "        <div className=\"messages\">\n",
      "          {messages.map((message, index) => (\n",
      "            <div key={index} className={`message ${message.sender}`}>\n",
      "              <span>{message.text}</span>\n",
      "            </div>\n",
      "          ))}\n",
      "        </div>\n",
      "        <div className=\"input-area\">\n",
      "          <input\n",
      "            type=\"text\"\n",
      "            value={input}\n",
      "            onChange={handleInputChange}\n",
      "            placeholder=\"Ask something about CUDA...\"\n",
      "          />\n",
      "          <button onClick={handleSend}>Send</button>\n",
      "        </div>\n",
      "      </div>\n",
      "    </div>\n",
      "  );\n",
      "}\n",
      "\n",
      "export default App;\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "\n",
      "- **State Management**: The `useState` hook is used to manage the input field and the list of messages in the chat.\n",
      "  \n",
      "- **handleInputChange**: Updates the input state every time the user types a character.\n",
      "\n",
      "- **handleSend**: Sends the user's message to the FastAPI backend and updates the chat with the response from the backend.\n",
      "\n",
      "- **fetch**: Makes a POST request to the FastAPI backend with the user's message. Expects a JSON response containing the chatbot's reply.\n",
      "\n",
      "- **Styling**: Basic CSS classes are assumed for styling. You can customize the styles in `App.css`.\n",
      "\n",
      "- **Error Handling**: Basic error handling is included to alert users if the backend request fails.\n",
      "\n",
      "This code is a starting point and can be expanded with more features like user authentication, improved error handling, loading states, etc. Remember to replace `'http://localhost:8000/chat'` with the actual endpoint of your FastAPI application.\n"
     ]
    }
   ],
   "source": [
    "# CREATE FRONTEND CODE\n",
    "from fileinput import filename\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's root directory to the Python path\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_vision_completion, get_completion, save_artifact, clean_llm_output\n",
    "from IPython.display import Image, display, Code, Markdown\n",
    "\n",
    "# Ensure you select a vision-capable model\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4o\")\n",
    "\n",
    "if not model_name:\n",
    "    print(\"Could not set up a valid LLM client. Please check your .env file and utils.py configuration.\")\n",
    "\n",
    "\n",
    "screenshot_url = \"https://i.ibb.co/gFb08jXz/screenshot.png\"\n",
    "display(Image(url=screenshot_url))\n",
    "\n",
    "generate_ui_prompt = f\"\"\"\n",
    "You are an expert frontend developer specializing in React and Tailwind CSS.\n",
    "\n",
    "Your task is to analyze the provided image of a login form and write the code for a single, self-contained React component that accurately replicates its design and layout.\n",
    "\n",
    "**Requirements:**\n",
    "- Use functional components.\n",
    "- Use Tailwind CSS for all styling. Do not use custom CSS or style tags.\n",
    "- Make sure the component is accessible, using appropriate HTML tags and attributes.\n",
    "- The output should be only the raw JSX code for the component.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Monolithic UI Component ---\")\n",
    "generated_monolithic_code = \"\"\n",
    "if model_name:\n",
    "    generated_monolithic_code = get_vision_completion(generate_ui_prompt, screenshot_url, client, model_name, api_provider)\n",
    "    cleaned_code = clean_llm_output(generated_monolithic_code, language='jsx')\n",
    "    display(Code(cleaned_code, language='jsx'))\n",
    "    save_artifact(cleaned_code, \"artifacts/component.jsx\")\n",
    "else:\n",
    "    print(\"Skipping UI generation because no valid model is configured.\")\n",
    "\n",
    "\n",
    "frontend_prompt = f\"\"\"\n",
    "You are a software engineer tasked with creating a frontend for the FastAPI application.\n",
    "\n",
    "Based on the provided component, create a frontend application for RAG powered documentation chatbot for CUDA.\n",
    "\n",
    "**Component Context:**\n",
    "![Component](component.jsx)\n",
    "\n",
    "Output only the raw React code for the frontend.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Frontend Code ---\")\n",
    "generated_frontend_code = get_completion(frontend_prompt, client, model_name, api_provider)\n",
    "print(generated_frontend_code)\n",
    "\n",
    "# CREATE FRONTEND CODE USING LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907444ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_code_prompt = f\"\"\"\n",
    "You are an expert software developer specializing in React and Python.\n",
    "\n",
    "Generate working RAG powered documentation chatbot for CUDA.\n",
    "\n",
    "**Requirements:**\n",
    "- Use React for the frontend.\n",
    "- Use Python for the backend.\n",
    "- Use FastAPI for the backend.\n",
    "- Use SQLite for the database.\n",
    "- Use LLM for the chatbot.\n",
    "- Use RAG for the chatbot.\n",
    "- Save backend code in backend folder.\n",
    "- Save frontend code in frontend folder.\n",
    "- Save database as .db file in the project root folder.\n",
    "- Use CUDA documentation (https://docs.nvidia.com/cuda/cuda-c-programming-guide/) as source documents.\n",
    "- Use artifacts/prd.md as the product requirements document.\n",
    "- Use artifacts/schema.sql as the database schema.\n",
    "- Use artifacts/component.jsx as the main page of the chatbot.\n",
    "- Use artifacts/component-diagram.png as the architecture of the chatbot.\n",
    "\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
